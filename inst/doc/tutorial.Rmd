marxan tutorial
============

### Overview

The marxan R package is designed to bring the entire Marxan workflow to R. It provides functions for preparing raw data for Marxan, running Marxan, and visualising Marxan results. It is designed to be fast: many of the computationally intensive operations are performed in C++ and have options to employ parallel processing. However, it also needs to be robust and flexible. Marxan users need to be able to change any aspect of a conservation planning scenario and the Marxan parameters with ease, but also be told off when they are doing something silly. To achieve this, the package makes extensive use of S4 classes as well as a combination of S3 and S4 dispatch methods.

### Introduction to MaRxaning
First, let's load the 'marxan' R package and some example data. The example data distributed with this package comes from the ['Introduction to Marxan'](http://marxan.net/courses.html).

```{r, eval=FALSE}
# load marxan R package
library(marxan)

# load example data
data(taspu, tasinvis)
```

Biodiversity features are represented using `RasterStack` objects. A `RasterStack` represents a collection of `RasterLayers`. Each `RasterLayer` describes the distribution of a biodiversity feature. In our example data, the `tasinvis` object is a `RasterStack` object that contains 63 `RasterLayers`. Each `RasterLayer` describes the distribution of a vegetation class in Tasmania (Australia). Ones indicate the presence of a vegetation class in an area and zeros indicate the absence of this class in the area. Let's take a look at the first 12 vegetation classes:

```{r, eval=FALSE}
# plot first 12 vegetation classes
# grey colors indicate absence
# green colors indicate presence
# try making the plotting window larger if 
# you only see gray
plot(tasinvis)
```

Planning units are represented using a `SpatialPolygons` object. Each polygon represents an individual planning unit. Here, in this example, the `taspu` object contains our planning units for Tasmania. This object has an the attribute table, and in it each unit is associated an id ('id' field), an acquisition cost ('cost' field), and a value indicating if the most of the unit is contained in an existing protected area ('status' field). Let's take a look at `taspu`:
```{r, eval=FALSE}
# the attribute table for a shapefile is stored
# in the data slot which can be accessed with @data
# print first 20 rows of attribute table
head(taspu@data)

# plot planning units
plot(taspu)

# plot planning units, 
# and colour by acquisition cost
spplot(taspu, 'cost')

# plot planning units, 
# and colour by present level of protection
# 0 = not already protected
# 2 = already protected
spplot(taspu, 'status')
```

Clearly, there is huge variation in acquisiton cost and many of the planning units are already in existing protected areas. However, to keep things simple for the moment, let's assume that all planning units have equal costs and that there are no protected areas in Tasmania. To do this, let's make a copy of `taspu` called `taspu2`, and change all the costs to 1, and set all the status values to 0. We will then use this copy, `taspu2`, to make some reserve systems.

```{r, eval=FALSE}
# copy taspu
taspu2<-taspu

# set costs
taspu2@data$cost<-1

# set status values
# note the 'L' after the zero is used to indicate
# that we mean the integer zero and not the decimal
# place number zero
taspu2@data$status<-0L

# show first 20 rows of taspu
# to check they are the same as before
head(taspu@data)

# show first 20 rows of taspu2
# to check they are different
head(taspu2@data)
```

Now, let's make some reserve systems. We can do this using the `marxan` function-- syntactic sugar for the conservation planner. This function automates the process of (1) taking planning unit and biodiversity feature data and turning it into input data for MARXAN, (2) saving the input data to a folder on the computer, (3) copying the MARXAN executable file to that folder, (4) running MARXAN, and finally (5) loading the MARXAN outputs into R. One line of R code; most of the Marxan workflow. 

Here, we will generate a portfolio of reserve systems that represent 20% of each vegetation class. We will also make use of parallel processing to greatly reduce run time. Note that some of the numbers below have an 'L' character after them, this is because we are specifying an integer and not a decimal place number. For instance, we cannot have a portfolio with 6.5 solutions.

```{r, eval=FALSE}
# argument to targets is level of protection
# argument to spf is the species penalty factor for each vegetation class
# argument to NCORES defines the number of threads for parallel processing
# argument to NUMREPS controls the number of solutions in our portfolio
# argument to BLM controls boundary length modifier
results<-marxan(taspu2, tasinvis, targets="20%", spf=1, NUMREPS=100L, NCORES=2L, BLM=0, lengthFactor=1e-5)
```

Well, that was easy. Apparently it worked; we can see the text MARXAN normally prints when we run it. Before we do anything, let's check that our vegetation classes are adequately represented. 

```{r, eval=FALSE}
# histogram of proportion of vegetation classes adequately
# represented in each solution
# if many of the solutions adequately represented the classes
# most of the bins would be close to 1, whereas if 
# the solutions failed to represent the classes most of the
# bins would be close to zero
hist(rowMeans(targetsmet(results)), freq=TRUE, xlim=c(0,1), las=1,
	main='Histogram of representation in portfolio',
	ylab='Frequency of solutions',
	xlab='Proportion of veg. classes adequately represented'
)
```

Now that we have formatted the data using the `marxan` function, we can also plot the distribution of the vegetation class in the planning units.

```{r, eval=FALSE}
# geoplot distribution of vegetation class 5
spplot(results, 5, var='occ')

# geoplot richness in planning units
# with a satellite base map
spplot(results, var='occ', basemap='satellite')
```

Unfortunately, all of the solutions in our portfolio have failed to meet the targets for the all vegetation classes. To fix this, we need to increase the species penalty factors (SPFs), and rerun MARXAN to generate a new portfolio of solutions.

If you recall, earlier we used the `marxan` function because it can pre-process the raw planning unit and feature data, run MARXAN, and load the results back into R. As a consequence, the `results` object has all the pre-processed data we need for the next MARXAN run. To reduce processing time and avoid re-running the same geoprocessing operations, we can re-use the pre-processed data in `results`. To do this, we will use the `update` function, to copy the pre-processed data in `results`, change the species penalty factors, rerun MARXAN, and load the new results back into R.

```{r, eval=FALSE}
# copy the MARXAN parameters and pre-processed data in results,
# update the SPF parameter for all species,
# run MARXAN,
# load the solutions back into R,
# store the solutions in results2
results2<-update(results, ~spp(1:63, spf=rep(100,63)))
```

Now we have a new portfolio of solutions, let's compare the proportion of vegetation classes adequately represented in each of the portfolios.

```{r, eval=FALSE}
# get levels of representation in each portfolio
results.repr<-rowMeans(targetsmet(results))
results2.repr<-rowMeans(targetsmet(results2))

# create 2 plotting areas in the one window
par(mfrow=c(1,2))

# histogram of first portfolio
hist(results.repr, freq=TRUE, xlim=c(0,1), las=1,
	ylab='Frequency of solutions',
	xlab='Proportion of veg. classes adequately represented',
	main="Level of representation with SPF=1"
)

# print best level of representation
print(max(results.repr))

# histogram of second portfolio
# if you see a giant single rectangle this means
# all the solutions have the same level of representation
hist(results2.repr, freq=TRUE, xlim=c(0,1), las=1,
	ylab='Frequency of solutions',
	xlab='Proportion of veg. classes adequately represented',
	main="Level of representation with SPF=100"
)

# print best level of representation
print(max(results2.repr))
```

The new portfolio has solutions that are on average much better at representing the vegetation classes. To see what these solutions look like, let's make some geoplots of individual solutions in `results2`. Let's also make a geoplot showing which planning units were most frequently selected in all the solutions in `results2`.

```{r, eval=FALSE}
# make a geoplot of the best solution
plot(results2, 0)

# make a geoplot of the second solution,
# with kickass google map background and transparent colors
plot(results2, 2, basemap='satellite', alpha=0.4)

# make a geoplot of planning unit selection frequencies,
# planning units with darker colours were more often
# selected for protection than those with lighter colours.
plot(results2, basemap='satellite', alpha=0.4)

# make a geoplot of selection frequencies using different colours
# see Color Brewer (http://colorbrewer2.org/) for available 
# colour ramps
plot(results2, colramp='YlGnBu')
```

That was neat. But all the solutions so far were made under the assumption that all planning units have equal acquisition costs and that Tasmania does not have any protected areas. For instance, our solutions might indicate that we should protect several really costly planning units, when instead, we could substitute several other cheap planning units and achieve the same level of representation for all the vegetation classes. Or maybe, several vegetation classes are already adequately represented in the protected areas in Tasmania, so we don't actually need to buy any more planning units to adequately protect these classes.

Similar to before, we will use the `update` function to re-use pre-processed data. This time we will use the `update` function to change the planning unit status and cost values.

```{r, eval=FALSE}
# get planning unit ids
pu.ids<-taspu@data$id

# get planning unit costs 
pu.costs<-taspu@data$cost

# get planning unit statuses
pu.status<-taspu@data$status

# copy input parameters and data in results2, 
# change planning unit costs and statuses
# rerun MARXAN,
# load outputs into R and store them in results3
results3<-update(results2, ~pu(pu.ids, cost=pu.costs, status=pu.status))
```

Now we have a third portfolio. Let's compare the previous portfolio based on unrealistic planning unit data with the new portfolio based on realistic planning unit data.

```{r, eval=FALSE}
# geoplot showing differences between the best solution in each portfolio
plot(results2, results3, i=0, j=0)

# geoplot showing differences between the third solution
# in results2 and the fifth solution in results3
plot(results2, results3, i=3, j=5)

# geoplot showing difference in selection frequencies between the two objects
# white colors indicate that units are already in a protected area
# blue colours indicate that units were more often selected in results2
# red  colours indicate that units were more often selected in results3
plot(results2, results3)
```

Explicitly considering real-world costs and existing protected areas has radically changed our prioritisations. This highlights the importance of incorporating real-world data into conservation planning. However, there still remains (at least) one issue with these solutions.

All the solutions in our current portfolio, `results3`, seem to be fairly fragmented. If implemented as protected areas, these solutions might be associated with poor connectivity and high maintenance costs. To reduce fragmentation, we can increase the boundary length modifier (BLM). However, in order to maintain adequate levels of representation for the vegetation classes, MARXAN will select more expensive planning units. How can we pick an appropriate BLM while still making sure the acquisition costs are adequate cost? Let's generate six more portfolios, each using a different BLM, and plot the trade-off between acquisition cost and fragmentation using the best solutions in each portfolio.

```{r, eval=FALSE}
## generate list of portfolios with different BLMS
# make vector BLM parameters to use
blm.pars=c(0, 100, 250, 500, 750, 1000)

# create list with different portfolio for each BLM
results4<-list()
for (i in seq_along(blm.pars)) {
	results4[[i]]<-update(results3, ~opt(BLM=blm.pars[i], NUMREPS=10L))
}

## extract data from portfolios
# create empty vectors to store values
cost<-c()
con<-c()
blm<-c()

# extract values for best solutions
for (i in seq_along(blm.pars)) {
	cost<-append(cost, summary(results4[[i]])[["Cost"]])
	con<-append(con, summary(results4[[i]])[["Connectivity"]])
	blm<-append(blm, rep(blm.pars[i], nrow(summary(results4[[i]]))))
}

## plot trade-off between shortfall and connectivity
# get colours for legend
legend.cols<-c("#FFFFB2", "#FED976", "#FEB24C", "#FD8D3C", "#F03B20", "#BD0026")
pt.cols<-legend.cols[match(blm, blm.pars)]

# reset plotting window
par(mfrow=c(1,1))

# plot trade-off data
# higher shortfall values means worse representation
# higher connectivity values mean more fragmentation
plot(cost~con, bg=pt.cols, col='black', ylab='Cost', xlab='Connectivity', pch=21,
	main='Trade-off between cost and connectivity')
abline(lm(cost~con))

# add legend
legend("topright", legend=blm.pars, col='black', pt.bg=legend.cols, pch=21, title='BLM')
```

Looking at this curve and depending on the total budget, you might decide that second portfolio in `results4` achieves an acceptable level of representation and fragmentation. Let's generate another portfolio of solutions with BLM=0.0001, and then make some geoplots to compare it to `results3`.

```{r, eval=FALSE}
# make new solutions with BLM=0.0001
results5<-update(results3, ~opt(BLM=0.0001))

# geoplot showing differences between the best solution in each portfolio
plot(results5, results3, i=0, j=0)

# geoplot showing difference in selection frequencies between the two objects
# black colours indicate that units are already in a protected area
# blue colours indicate that units were more often selected in results4[[2]],
# and red colours indicate that they were often selected in results3
plot(results5, results3)
```

So now, in our final portfolio, we have one hundred solutions. How can we compare them all and decide on a final prioritisation to implement? We don't time time to make 100 maps; while the maps this R package makes are pretty, they are not that pretty. Instead, we could make some dotcharts that let us compare various properties of the solutions.

```{r, eval=FALSE}
# make dotchart showing the score of each solution
# the score describes the overall value of the prioritisations based on our criteria
# the lower the value, the better the solution
# the best solution is coloured in red
dotchart(results5, var='score')

# make dotchart showing the connectivity of the solutions
# solutions with lower values are more clustered
# solutions with higher values are more fragmented
# argument to n specifies the number of solutions to plot
# argument to nbest specifies number of solutions to colour in red
dotchart(results5, var='con', nbest=5, n=20)
```

Dotcharts are useful if we want to know which solutions rank better according different performance metrics. However, they don't show us the how the solutions vary in their  planning unit selections or how well they represent different biodiversity features. For instance, maybe the solutions in our portfolio fall into two distinct groups: one group solutions that sites reserves in south-east Tasmania and another group that sites reserves in north-east Tasmania. Or maybe one group over-represents a subset of biodiversity features (eg. vegetation classes 1-10), while the other group of solutions over-represent another subset of features (eg. classes 20-50)? If we had some way of effectively grouping the solutions, then we wouldn't need to investigate all the solutions in our portfolio, we could just look at a few solutions from each group. So, how can we summarise the main themes of variation in our portfolio?

Fortunately, statisticians solved this problem a long time ago. We can use ordination techniques to create a few variables that describe commonalities among the solutions, and visualise the main sources of variation in a small number of dimensions.

```{r, eval=FALSE}
## dendrogram showing differences between solutions based on which planning units 
## were selected (using Bray-Curtis distances by default)
# the solutions are shown at the (bottom) tips of the tree.
# solutions that occupy nearby places in tree
# have similar sets of planning units selected.
# the best prioritisation is coloured in red.
dendrogram(results5, type='dist', var='selections')

## same dendrogram as above but with the best 10 prioritisations coloured in red
# if all the red lines connect together at the bottom of the dendrogram
# this means that all the best prioritisations are really similar to each other,
# but if they connect near the top of the dendrogram then this means that
# some of the best prioritisations have totally different sets of planning units
# selected for protection.
dendrogram(results5, type='dist', var='selections', nbest=10)

## ordination plot showing differences between solutions based on the number of units
## occupied by each vegetation class (using MDS with Bray-Curtis distances)
# we can also use multivariate techniques to see how the solutions vary
# based on how well they represent different vegetation classes.
# the numbers indicate solution indices.
# solutions closer to each other in this plot have more
# similar levels of representation for the same species.
# the size of the numbers indicate solution quality,
# the bigger the number, the higher the solution score.
ordiplot(results5, type='mds', var='occheld', method='bray')

# ordination plot showing differences between solutions based on the amount held 
# by each vegetation class (using a principle components analysis)
# labels are similar to the previous plot.
# the arrows indicate the variable loadings.
ordiplot(results5, type='pca', var='amountheld')
```

But which prioritisation should we actually implement? You want me to tell you? 

### I'm sorry, Dave. I'm afraid I can't do that. I'm just a computer--a decision support tool.

<!--
%\VignetteEngine{knitr::knitr}
%\VignetteIndexEntry{marxan R package tutorial}
-->

